{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabDesign/blob/gamma/af/examples/predict_bb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AlphaFold2_bigbang\n",
        "WARNING: this is an experimental notebook implementing the the big bang initialization described in:\n",
        "\n",
        "- **An atlas of protein homo-oligomerization across domains of life**\n",
        "  - H Schweke, T Levin, M Pacesa, CA Goverde, P Kumar, Y Duhoo LJ Dornfeld, B Dubreuil, S Georgeon, S Ovchinnikov, DN Woolfson, BE Correia, S Dey, ED Levy\n",
        "  - https://doi.org/10.1101/2023.06.09.544317"
      ],
      "metadata": {
        "id": "-ODkDJyNnBOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title setup\n",
        "unified_memory = True\n",
        "import os, time, gc\n",
        "if unified_memory:\n",
        "  ENV = {\"TF_FORCE_UNIFIED_MEMORY\":\"1\", \"XLA_PYTHON_CLIENT_MEM_FRACTION\":\"4.0\"}\n",
        "  for k,v in ENV.items(): os.environ[k] = v\n",
        "if not os.path.isdir(\"params\"):\n",
        "  # get code\n",
        "  print(\"installing ColabDesign\")\n",
        "  os.system(\"(mkdir params; apt-get install aria2 -qq; \\\n",
        "  aria2c -q -x 16 https://storage.googleapis.com/alphafold/alphafold_params_2022-12-06.tar; \\\n",
        "  tar -xf alphafold_params_2022-12-06.tar -C params; touch params/done.txt )&\")\n",
        "\n",
        "  os.system(\"pip -q install git+https://github.com/sokrypton/ColabDesign.git@gamma\")\n",
        "  os.system(\"ln -s /usr/local/lib/python3.*/dist-packages/colabdesign colabdesign\")\n",
        "  os.system(\"wget https://raw.githubusercontent.com/sokrypton/ColabFold/main/colabfold/colabfold.py -O colabfold_utils.py\")\n",
        "\n",
        "  # install hhsuite\n",
        "  print(\"installing HHsuite\")\n",
        "  os.makedirs(\"hhsuite\", exist_ok=True)\n",
        "  os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C hhsuite/\")\n",
        "\n",
        "  print(\"installing AnAnaS\")\n",
        "  os.system(\"wget -qnc https://files.ipd.uw.edu/krypton/ananas\")\n",
        "  os.system(\"wget -qnc https://files.ipd.uw.edu/krypton/make_symmdef_file.pl\")\n",
        "  os.system(\"chmod +x ananas\")\n",
        "\n",
        "  # download params\n",
        "  if not os.path.isfile(\"params/done.txt\"):\n",
        "    print(\"downloading AlphaFold params\")\n",
        "    while not os.path.isfile(\"params/done.txt\"):\n",
        "      time.sleep(5)\n",
        "if \"hhsuite\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += \":hhsuite/bin:hhsuite/scripts\"\n",
        "\n",
        "import re, tempfile\n",
        "from IPython.display import HTML\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "from colabdesign import mk_af_model, clear_mem\n",
        "from colabdesign.af.contrib import predict\n",
        "from colabdesign.af.contrib.cyclic import add_cyclic_offset\n",
        "from colabdesign.shared.protein import _np_rmsd, _np_kabsch\n",
        "from colabdesign.shared.plot import plot_pseudo_3D, pymol_cmap\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from colabfold_utils import run_mmseqs2\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "def clear_mem():\n",
        "  backend = jax.lib.xla_bridge.get_backend()\n",
        "  for buf in backend.live_buffers(): buf.delete()\n",
        "\n",
        "def get_pdb(pdb_code=\"\"):\n",
        "  if pdb_code is None or pdb_code == \"\":\n",
        "    upload_dict = files.upload()\n",
        "    pdb_string = upload_dict[list(upload_dict.keys())[0]]\n",
        "    with open(\"tmp.pdb\",\"wb\") as out: out.write(pdb_string)\n",
        "    return \"tmp.pdb\"\n",
        "  elif os.path.isfile(pdb_code):\n",
        "    return pdb_code\n",
        "  elif len(pdb_code) == 4:\n",
        "    os.makedirs(\"tmp\",exist_ok=True)\n",
        "    os.system(f\"wget -qnc https://files.rcsb.org/download/{pdb_code}.cif -P tmp/\")\n",
        "    return f\"tmp/{pdb_code}.cif\"\n",
        "  else:\n",
        "    os.makedirs(\"tmp\",exist_ok=True)\n",
        "    os.system(f\"wget -qnc https://alphafold.ebi.ac.uk/files/AF-{pdb_code}-F1-model_v4.pdb -P tmp/\")\n",
        "    return f\"tmp/AF-{pdb_code}-F1-model_v4.pdb\"\n",
        "\n",
        "def run_hhalign(query_sequence, target_sequence, query_a3m=None, target_a3m=None):\n",
        "  with tempfile.NamedTemporaryFile() as tmp_query, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_target, \\\n",
        "  tempfile.NamedTemporaryFile() as tmp_alignment:\n",
        "    if query_a3m is None:\n",
        "      tmp_query.write(f\">Q\\n{query_sequence}\\n\".encode())\n",
        "      tmp_query.flush()\n",
        "      query_a3m = tmp_query.name\n",
        "    if target_a3m is None:\n",
        "      tmp_target.write(f\">T\\n{target_sequence}\\n\".encode())\n",
        "      tmp_target.flush()\n",
        "      target_a3m = tmp_target.name\n",
        "    os.system(f\"hhalign -hide_cons -i {query_a3m} -t {target_a3m} -o {tmp_alignment.name}\")\n",
        "    X, start_indices = predict.parse_hhalign_output(tmp_alignment.name)\n",
        "  return X, start_indices\n",
        "\n",
        "def run_do_not_align(query_sequence, target_sequence, **arg):\n",
        "  return [query_sequence,target_sequence],[0,0]\n",
        "\n",
        "def run_hhfilter(input, output, id=90, qid=10):\n",
        "  os.system(f\"hhfilter -id {id} -qid {qid} -i {input} -o {output}\")\n",
        "\n",
        "@jax.jit\n",
        "def get_coevolution(X):\n",
        "  '''given one-hot encoded MSA, return contacts'''\n",
        "  Y = jax.nn.one_hot(X,22)\n",
        "  N,L,A = Y.shape\n",
        "  Y_flat = Y.reshape(N,-1)\n",
        "  # covariance\n",
        "  c = jnp.cov(Y_flat.T)\n",
        "\n",
        "  # inverse covariance\n",
        "  shrink = 4.5/jnp.sqrt(N) * jnp.eye(c.shape[0])\n",
        "  ic = jnp.linalg.inv(c + shrink)\n",
        "\n",
        "  # partial correlation coefficient\n",
        "  ic_diag = jnp.diag(ic)\n",
        "  pcc = ic / jnp.sqrt(ic_diag[:,None] * ic_diag[None,:])\n",
        "\n",
        "  raw = jnp.sqrt(jnp.square(pcc.reshape(L,A,L,A)[:,:20,:,:20]).sum((1,3)))\n",
        "  i = jnp.arange(L)\n",
        "  raw = raw.at[i,i].set(0)\n",
        "  # do apc\n",
        "  ap = raw.sum(0,keepdims=True) * raw.sum(1,keepdims=True) / raw.sum()\n",
        "  return (raw - ap).at[i,i].set(0)\n",
        "\n",
        "def plot_3D(aux, Ls, file_name, show=False):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  xyz = aux[\"atom_positions\"][:,1]\n",
        "  xyz = xyz @ _np_kabsch(xyz, xyz, return_v=True, use_jax=False)\n",
        "  ax = plt.subplot(1,2,1)\n",
        "  if len(Ls) > 1:\n",
        "    plt.title(\"chain\")\n",
        "    c = np.concatenate([[n]*L for n,L in enumerate(Ls)])\n",
        "    plot_pseudo_3D(xyz=xyz, c=c, cmap=pymol_cmap, cmin=0, cmax=39, Ls=Ls, ax=ax)\n",
        "  else:\n",
        "    plt.title(\"length\")\n",
        "    plot_pseudo_3D(xyz=xyz, Ls=Ls, ax=ax)\n",
        "  plt.axis(False)\n",
        "  ax = plt.subplot(1,2,2)\n",
        "  plt.title(\"plddt\")\n",
        "  plot_pseudo_3D(xyz=xyz, c=aux[\"plddt\"], cmin=0.5, cmax=0.9, Ls=Ls, ax=ax)\n",
        "  plt.axis(False)\n",
        "  plt.savefig(file_name, dpi=200, bbox_inches='tight')\n",
        "  plt.show() if show else plt.close()\n",
        "\n",
        "def clean_seq(sequence):\n",
        "  sequence = sequence.upper()\n",
        "  sequence = re.sub(\"[^A-Z:/()]\", \"\", sequence.upper())\n",
        "  sequence = re.sub(\"\\(\",\":(\", sequence)\n",
        "  sequence = re.sub(\"\\)\",\"):\", sequence)\n",
        "  sequence = re.sub(\":+\",\":\",sequence)\n",
        "  sequence = re.sub(\"/+\",\"/\",sequence)\n",
        "  sequence = re.sub(\"^[:/]+\",\"\",sequence)\n",
        "  sequence = re.sub(\"[:/]+$\",\"\",sequence)\n",
        "  return sequence\n",
        "\n",
        "def clean_job(jobname):\n",
        "  jobname = re.sub(r'\\W+', '', jobname)\n",
        "  return jobname\n",
        "\n",
        "class ColabFold:\n",
        "  ##############################################################################\n",
        "  # prep_inputs\n",
        "  ##############################################################################\n",
        "  def prep_inputs(self, sequence,\n",
        "                  jobname=\"test\",\n",
        "                  copies=1,\n",
        "                  # msa options\n",
        "                  msa_method=\"mmseqs2\", pair_mode=\"unpaired_paired\",\n",
        "                  # filtering options\n",
        "                  cov=75,id=90,qid=0,do_not_filter=False,\n",
        "                  # template options\n",
        "                  template_mode=\"none\", pdb=\"\", chain=\"A\", rm_template_seq=False,\n",
        "                  propagate_to_copies=False, do_not_align=False):\n",
        "\n",
        "    # filter options\n",
        "    self._use_templates = template_mode in [\"mmseqs2\",\"custom\"]\n",
        "    self._rm_sidechain = self._rm_sequence = rm_template_seq\n",
        "\n",
        "    # process sequence\n",
        "    sequences = sequence.split(\":\")\n",
        "    u_sequences = predict.get_unique_sequences(sequences)\n",
        "    self._u_cyclic = [x.startswith(\"(\") for x in u_sequences]\n",
        "    self._u_sub_lengths = [[len(y) for y in x.split(\"/\")] for x in u_sequences]\n",
        "    u_sequences = [x.replace(\"(\",\"\").replace(\")\",\"\").replace(\"/\",\"\") for x in u_sequences]\n",
        "    if len(sequences) > len(u_sequences):\n",
        "      print(\"WARNING: use copies to define homooligomers\")\n",
        "    self._u_lengths = [len(x) for x in u_sequences]\n",
        "    sub_seq = \"\".join(u_sequences)\n",
        "    seq = sub_seq * copies\n",
        "\n",
        "    jobname = f\"{jobname}_{predict.get_hash(seq)[:5]}\"\n",
        "    def check(folder): return os.path.exists(folder)\n",
        "    if check(jobname):\n",
        "      n = 0\n",
        "      while check(f\"{jobname}_{n}\"): n += 1\n",
        "      jobname = f\"{jobname}_{n}\"\n",
        "\n",
        "    print(\"jobname\",jobname)\n",
        "    print(f\"length={self._u_lengths} copies={copies}\")\n",
        "\n",
        "    self._input_opts = {\n",
        "      \"sequence\":u_sequences,\n",
        "      \"copies\":copies,\n",
        "      \"msa_method\":msa_method,\n",
        "      \"pair_mode\":pair_mode,\n",
        "      \"do_not_filter\":do_not_filter,\n",
        "      \"cov\":cov,\n",
        "      \"id\":id,\n",
        "      \"template_mode\":template_mode,\n",
        "      \"propagate_to_copies\":propagate_to_copies,\n",
        "    }\n",
        "\n",
        "    # GET MSA\n",
        "    os.makedirs(jobname, exist_ok=True)\n",
        "    self._Ls = [len(x) for x in u_sequences]\n",
        "    if msa_method == \"mmseqs2\":\n",
        "      msa, deletion_matrix = predict.get_msa(u_sequences, jobname,\n",
        "        mode=pair_mode,\n",
        "        cov=cov, id=id, qid=qid, max_msa=4096,\n",
        "        do_not_filter=do_not_filter,\n",
        "        mmseqs2_fn=lambda *x: run_mmseqs2(*x, user_agent=\"colabdesign/gamma\"),\n",
        "        hhfilter_fn=run_hhfilter)\n",
        "\n",
        "    elif msa_method == \"single_sequence\":\n",
        "      with open(f\"{jobname}/msa.a3m\",\"w\") as a3m:\n",
        "        a3m.write(f\">{jobname}\\n{sub_seq}\\n\")\n",
        "      msa, deletion_matrix = predict.parse_a3m(f\"{jobname}/msa.a3m\")\n",
        "\n",
        "    else:\n",
        "      msa_format = msa_method.split(\"_\")[1]\n",
        "      print(f\"upload {msa_method}\")\n",
        "      msa_dict = files.upload()\n",
        "      lines = []\n",
        "      for k,v in msa_dict.items():\n",
        "        lines += v.decode().splitlines()\n",
        "      input_lines = []\n",
        "      for line in lines:\n",
        "        line = line.replace(\"\\x00\",\"\")\n",
        "        if len(line) > 0 and not line.startswith('#'):\n",
        "          input_lines.append(line)\n",
        "      with open(f\"{jobname}/msa.{msa_format}\",\"w\") as msa:\n",
        "        msa.write(\"\\n\".join(input_lines))\n",
        "      if msa_format != \"a3m\":\n",
        "        os.system(f\"perl hhsuite/scripts/reformat.pl {msa_format} a3m {jobname}/msa.{msa_format} {jobname}/msa.a3m\")\n",
        "      if do_not_filter:\n",
        "        os.system(f\"hhfilter -qid 0 -id 100 -cov 0 -i {jobname}/msa.a3m -o {jobname}/msa.filt.a3m\")\n",
        "      else:\n",
        "        os.system(f\"hhfilter -qid {qid} -id {id} -cov {cov} -i {jobname}/msa.a3m -o {jobname}/msa.filt.a3m\")\n",
        "      msa, deletion_matrix = predict.parse_a3m(f\"{jobname}/msa.filt.a3m\")\n",
        "\n",
        "    if len(msa) > 1:\n",
        "      predict.plot_msa(msa, self._Ls)\n",
        "      plt.savefig(f\"{jobname}/msa_feats.png\", dpi=200, bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n",
        "    ##################\n",
        "    if self._use_templates:\n",
        "      print(\"aligning template\")\n",
        "      template_msa = f\"{jobname}/msa.a3m\"\n",
        "      if template_mode == \"mmseqs2\":\n",
        "        predict.get_msa(u_sequences, jobname,\n",
        "          mode=\"unpaired\",\n",
        "          mmseqs2_fn=lambda *x: run_mmseqs2(*x, user_agent=\"colabdesign/gamma\"),\n",
        "          do_not_filter=True,\n",
        "          do_not_return=True,\n",
        "          output_a3m=f\"{jobname}/msa_tmp.a3m\")\n",
        "        template_msa = f\"{jobname}/msa_tmp.a3m\"\n",
        "        if not propagate_to_copies and copies > 1:\n",
        "          new_msa = []\n",
        "          with open(template_msa, \"r\") as handle:\n",
        "            for line in handle:\n",
        "              if not line.startswith(\">\"):\n",
        "                new_msa.append(line.rstrip())\n",
        "          with open(template_msa, \"w\") as handle:\n",
        "            for n,seq in enumerate(new_msa):\n",
        "              handle.write(f\">{n}\\n{seq*copies}\\n\")\n",
        "\n",
        "        templates = {}\n",
        "        print(\"ID\\tpdb\\tcid\\tevalue\")\n",
        "        for line in open(f\"{jobname}/msa/_env/pdb70.m8\",\"r\"):\n",
        "          p = line.rstrip().split()\n",
        "          M,target_id,qid,e_value = p[0],p[1],p[2],p[10]\n",
        "          M = int(M)\n",
        "          if M not in templates:\n",
        "            templates[M] = []\n",
        "          if len(templates[M]) < 4:\n",
        "            print(f\"{int(M)}\\t{target_id}\\t{qid}\\t{e_value}\")\n",
        "            templates[M].append(target_id)\n",
        "        if len(templates) == 0:\n",
        "          self._use_templates = False\n",
        "          print(\"ERROR: no templates found...\")\n",
        "        else:\n",
        "          Ms = sorted(list(templates.keys()))\n",
        "          pdbs,chains = [],[]\n",
        "          for M in Ms:\n",
        "            for n,target_id in enumerate(templates[M]):\n",
        "              pdb_id,chain_id = target_id.split(\"_\")\n",
        "              if len(pdbs) < n+1:\n",
        "                pdbs.append([])\n",
        "                chains.append([])\n",
        "              pdbs[n].append(pdb_id)\n",
        "              chains[n].append(chain_id)\n",
        "          print(pdbs)\n",
        "      else:\n",
        "        pdbs,chains = [pdb],[chain]\n",
        "\n",
        "    if self._use_templates:\n",
        "      self._input_opts.update({\"pdbs\":pdbs, \"chains\":chains})\n",
        "      batches = []\n",
        "      for pdb,chain in zip(pdbs,chains):\n",
        "        query_seq = \"\".join(u_sequences)\n",
        "        batch = predict.get_template_feats(pdb, chain,\n",
        "          query_seq=query_seq,\n",
        "          query_a3m=template_msa,\n",
        "          copies=copies,\n",
        "          propagate_to_copies=propagate_to_copies,\n",
        "          use_seq=not self._rm_sequence,\n",
        "          get_pdb_fn=get_pdb,\n",
        "          align_fn=run_do_not_align if do_not_align else run_hhalign)\n",
        "        batches.append(batch)\n",
        "\n",
        "      # for display\n",
        "      plt.figure(figsize=(3*len(batches),3))\n",
        "      for n,batch in enumerate(batches):\n",
        "        plt.subplot(1,len(batches),n+1)\n",
        "        plt.title(f\"template features {n+1}\")\n",
        "        dgram = batch[\"dgram\"].argmax(-1).astype(float)\n",
        "        dgram[batch[\"dgram\"].sum(-1) == 0] = np.nan\n",
        "        Ln = dgram.shape[0]\n",
        "        plt.imshow(dgram, extent=(0, Ln, Ln, 0))\n",
        "        predict.plot_ticks(self._Ls * copies)\n",
        "      plt.savefig(f\"{jobname}/template_feats.png\", dpi=200, bbox_inches='tight')\n",
        "      plt.show()\n",
        "    else:\n",
        "      batches = [None]\n",
        "\n",
        "    ################\n",
        "\n",
        "    self._sequence = sequence\n",
        "    self._jobname = jobname\n",
        "    self._msa = msa\n",
        "    self._deletion_matrix = deletion_matrix\n",
        "    self._batches = batches\n",
        "    self._copies = copies\n",
        "\n",
        "  ##############################################################################\n",
        "  # prep_model\n",
        "  ##############################################################################\n",
        "  def prep_model(self,\n",
        "    # model options\n",
        "    model_type=\"auto\",\n",
        "    rank_by=\"auto\",\n",
        "    debug=False,\n",
        "    use_initial_guess=False,\n",
        "    use_initial_atom_pos=False,\n",
        "    # msa options\n",
        "    num_msa=512,\n",
        "    num_extra_msa=1024,\n",
        "    use_cluster_profile=True):\n",
        "    multi = len(self._u_lengths) > 1 or self._copies > 1\n",
        "\n",
        "    if model_type == \"monomer (ptm)\":\n",
        "      use_multimer = False\n",
        "      pseudo_multimer = False\n",
        "    elif model_type == \"multimer (v3)\":\n",
        "      use_multimer = True\n",
        "      pseudo_multimer = False\n",
        "    elif model_type == \"pseudo_multimer (v3)\":\n",
        "      use_multimer = True\n",
        "      pseudo_multimer = True\n",
        "    elif multi:\n",
        "      use_multimer = True\n",
        "      pseudo_multimer = False\n",
        "    else:\n",
        "      use_multimer = False\n",
        "      pseudo_multimer = False\n",
        "\n",
        "    if rank_by == \"auto\":\n",
        "      rank_by = \"multi\" if multi else \"plddt\"\n",
        "    self._rank_by = rank_by\n",
        "\n",
        "    self._model_opts = {\n",
        "        \"num_msa\":num_msa,\n",
        "        \"num_extra_msa\":num_extra_msa,\n",
        "        \"num_templates\":len(self._batches),\n",
        "        \"use_cluster_profile\":use_cluster_profile,\n",
        "        \"use_multimer\":use_multimer,\n",
        "        \"pseudo_multimer\":pseudo_multimer,\n",
        "        \"use_templates\":self._use_templates,\n",
        "        \"use_batch_as_template\":False,\n",
        "        \"use_dgram\":True,\n",
        "        \"protocol\":\"hallucination\",\n",
        "        \"best_metric\":rank_by,\n",
        "        \"optimize_seq\":False,\n",
        "        \"debug\":debug,\n",
        "        \"clear_prev\":False,\n",
        "        \"use_initial_guess\":use_initial_guess,\n",
        "        \"use_initial_atom_pos\":use_initial_atom_pos,\n",
        "    }\n",
        "\n",
        "    # initialize the model\n",
        "    if hasattr(self,\"af\"):\n",
        "      # reuse the model and/or params if already initialized\n",
        "      if self._model_opts != self.__model_opts:\n",
        "        if self._model_opts[\"use_multimer\"] == self.af._args[\"use_multimer\"] \\\n",
        "        and self._model_opts[\"use_templates\"] == self.af._args[\"use_templates\"]:\n",
        "          old_params = dict(zip(self.af._model_names,self.af._model_params))\n",
        "        else:\n",
        "          print(\"loading alphafold params\")\n",
        "          old_params = {}\n",
        "          clear_mem()\n",
        "        self.af = mk_af_model(old_params=old_params,\n",
        "                              use_mlm=True, # can be disabled later with 0% masking\n",
        "                              **self._model_opts)\n",
        "        self.__model_opts = predict.copy_dict(self._model_opts)\n",
        "    else:\n",
        "      print(\"loading alphafold params\")\n",
        "      self.af = mk_af_model(use_mlm=True, **self._model_opts)\n",
        "      self.__model_opts = predict.copy_dict(self._model_opts)\n",
        "\n",
        "    # prep inputs\n",
        "    self.af.prep_inputs(self._u_lengths, copies=self._copies, seed=0)\n",
        "    self._print_key = [\"plddt\",\"ptm\"]\n",
        "    if len(self.af._lengths) > 1: self._print_key += [\"i_ptm\", \"multi\"]\n",
        "\n",
        "    # for contact map\n",
        "    self.af.set_opt(\"con\",cutoff=8.0)\n",
        "    # set templates\n",
        "    if self._use_templates:\n",
        "      # interchain masking determined by dgram\n",
        "      self.af._inputs[\"interchain_mask\"] = np.full_like(self.af._inputs[\"interchain_mask\"],True)\n",
        "      for n,batch in enumerate(self._batches):\n",
        "        self.af.set_template(batch=batch, n=n)\n",
        "      self.af.set_opt(\"template\",\n",
        "                rm_sc=self._rm_sidechain,\n",
        "                rm_seq=self._rm_sequence)\n",
        "    # set msa\n",
        "    self.af.set_msa(self._msa, self._deletion_matrix)\n",
        "\n",
        "    # set chainbreaks\n",
        "    L_prev = 0\n",
        "    for n,l in enumerate(self._u_sub_lengths * self._copies):\n",
        "      for L_i in l[:-1]:\n",
        "        self.af._inputs[\"residue_index\"][L_prev+L_i:] += 32\n",
        "        L_prev += L_i\n",
        "      L_prev += l[-1]\n",
        "\n",
        "    # set cyclic constraints\n",
        "    i_cyclic = [n for n, c in enumerate(self._u_cyclic * self._copies) if c]\n",
        "    if len(i_cyclic) > 0:\n",
        "      add_cyclic_offset(self.af,i_cyclic)\n",
        "  #############################################\n",
        "  # run_alphafold\n",
        "  #############################################\n",
        "  def run_alphafold(self,\n",
        "    #model options\n",
        "    model = \"all\",\n",
        "    num_recycles = 6,\n",
        "    recycle_early_stop_tolerance = 0.5,\n",
        "    select_best_across_recycles = False,\n",
        "    #stochastic options\n",
        "    use_mlm = True,\n",
        "    use_dropout = False,\n",
        "    seed = 0,\n",
        "    num_seeds = 1,\n",
        "    #extras\n",
        "    show_images = True,\n",
        "  ):\n",
        "    self._run_opts = {\n",
        "      \"seed\":seed,\n",
        "      \"use_mlm\":use_mlm,\n",
        "      \"use_dropout\":use_dropout,\n",
        "      \"num_recycles\":num_recycles,\n",
        "      \"model\":model,\n",
        "      \"select_best_across_recycles\":select_best_across_recycles,\n",
        "      \"recycle_early_stop_tolerance\":recycle_early_stop_tolerance\n",
        "    }\n",
        "\n",
        "    # decide which models to use\n",
        "    if model == \"all\": models = self.af._model_names\n",
        "    else: models = [self.af._model_names[int(model) - 1]]\n",
        "\n",
        "    # set options\n",
        "    self.af.set_opt(\"mlm\", replace_fraction=0.15 if use_mlm else 0.0)\n",
        "\n",
        "    pdb_path = f\"{self._jobname}/pdb\"\n",
        "    os.makedirs(pdb_path, exist_ok=True)\n",
        "\n",
        "    # keep track of results\n",
        "    self._info = []\n",
        "    self.af._tmp = {\"traj\":{\"seq\":[],\"xyz\":[],\"plddt\":[],\"pae\":[]},\n",
        "                     \"log\":[],\"best\":{}}\n",
        "\n",
        "    # run\n",
        "    print(\"running prediction\")\n",
        "    with open(f\"{self._jobname}/log.txt\",\"w\") as handle:\n",
        "      # go through all seeds\n",
        "      seeds = list(range(seed,seed+num_seeds))\n",
        "      for seed in seeds:\n",
        "        self.af.set_seed(seed)\n",
        "        # go through all models\n",
        "        for model in models:\n",
        "          recycle = 0\n",
        "          self.af._inputs.pop(\"prev\",None)\n",
        "          stop_recycle = False\n",
        "          prev_pos = None\n",
        "          # go through all recycles\n",
        "          while recycle < num_recycles + 1:\n",
        "            print_str = f\"seed={seed} model={model} recycle={recycle}\"\n",
        "            self.af.predict(dropout=use_dropout, models=[model], verbose=False)\n",
        "\n",
        "            # set previous inputs\n",
        "            self.af._inputs[\"prev\"] = self.af.aux[\"prev\"]\n",
        "            if self.af._args[\"use_initial_atom_pos\"]:\n",
        "              self.af._inputs[\"initial_atom_pos\"] = self.af.aux[\"atom_positions\"]\n",
        "\n",
        "            # save results\n",
        "            if len(self.af._lengths) > 1:\n",
        "              self.af.aux[\"log\"][\"multi\"] = 0.8 * self.af.aux[\"log\"][\"i_ptm\"] + 0.2 * self.af.aux[\"log\"][\"ptm\"]\n",
        "            self.af.save_current_pdb(f\"{pdb_path}/{model}_r{recycle}_seed{seed}.pdb\")\n",
        "\n",
        "            # print metrics\n",
        "            for k in self._print_key: print_str += f\" {k}={self.af.aux['log'][k]:.3f}\"\n",
        "\n",
        "            # early stop check\n",
        "            current_pos = self.af.aux[\"atom_positions\"][:,1]\n",
        "            if recycle > 0:\n",
        "              rmsd_tol = _np_rmsd(prev_pos, current_pos, use_jax=False)\n",
        "              if rmsd_tol < recycle_early_stop_tolerance:\n",
        "                stop_recycle = True\n",
        "              print_str += f\" rmsd_tol={rmsd_tol:.3f}\"\n",
        "            prev_pos = current_pos\n",
        "            # print metrics\n",
        "            print(print_str); handle.write(f\"{print_str}\\n\")\n",
        "\n",
        "            tag = f\"{model}_r{recycle}_seed{seed}\"\n",
        "            if select_best_across_recycles:\n",
        "              self._info.append([tag,print_str,self.af.aux[\"log\"][self._rank_by]])\n",
        "              self.af._save_results(save_best=True,\n",
        "                best_metric=self._rank_by, metric_higher_better=True,\n",
        "                verbose=False)\n",
        "              self.af._k += 1\n",
        "\n",
        "            recycle += 1\n",
        "            if stop_recycle: break\n",
        "\n",
        "          if not select_best_across_recycles:\n",
        "            self._info.append([tag,print_str, self.af.aux[\"log\"][self._rank_by]])\n",
        "            self.af._save_results(save_best=True,\n",
        "                            best_metric=self._rank_by, metric_higher_better=True,\n",
        "                            verbose=False)\n",
        "            self.af._k += 1\n",
        "\n",
        "          # save current results\n",
        "          plot_3D(self.af.aux, self._Ls * self._copies, f\"{pdb_path}/{model}_seed{seed}.pdf\", show=show_images)\n",
        "          predict.plot_confidence(self.af.aux[\"plddt\"]*100, self.af.aux[\"pae\"], self._Ls * self._copies)\n",
        "          plt.savefig(f\"{pdb_path}/{model}_seed{seed}.png\", dpi=200, bbox_inches='tight')\n",
        "          plt.close()\n",
        "\n",
        "    # save best results\n",
        "    rank = np.argsort([x[2] for x in self._info])[::-1][:5]\n",
        "    print(f\"best_tag={self._info[rank[0]][0]} {self._info[rank[0]][1]}\")\n",
        "\n",
        "    self._aux_best = self.af._tmp[\"best\"][\"aux\"]\n",
        "    self.af.save_pdb(f\"{pdb_path}/best.pdb\")\n",
        "    np.savez_compressed(f\"{pdb_path}/best.npz\",\n",
        "                        plddt=self._aux_best[\"plddt\"].astype(np.float16),\n",
        "                        pae=self._aux_best[\"pae\"].astype(np.float16),\n",
        "                        tag=np.array(self._info[rank[0]][0]),\n",
        "                        metrics=np.array(self._info[rank[0]][1]))\n",
        "    np.savez_compressed(f\"{pdb_path}/all.npz\",\n",
        "                        plddt=np.array(self.af._tmp[\"traj\"][\"plddt\"], dtype=np.float16),\n",
        "                        pae=np.array(self.af._tmp[\"traj\"][\"pae\"], dtype=np.float16),\n",
        "                        tag=np.array([x[0] for x in self._info]),\n",
        "                        metrics=np.array([x[1] for x in self._info]))\n",
        "    plot_3D(self._aux_best, self._Ls * self._copies, f\"{pdb_path}/best.pdf\", show=False)\n",
        "    predict.plot_confidence(self._aux_best[\"plddt\"]*100, self._aux_best[\"pae\"], self._Ls * self._copies)\n",
        "    plt.savefig(f\"{pdb_path}/best.png\", dpi=200, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# initialize\n",
        "cf = ColabFold()"
      ],
      "metadata": {
        "id": "NsRHgcGPs4fL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title prep_inputs\n",
        "sequence = \"MAAVTGIALGMIETRGLVPAIEAADAMTKAAEVRLVGRQFVGGGYVTVLVRGETGAVNAAVRAGADACERVGDGLVAAHIIARVHSEVENILPKAPEA\" #@param {type:\"string\"}\n",
        "jobname = \"test\" #@param {type:\"string\"}\n",
        "\n",
        "sequence = clean_seq(sequence)\n",
        "jobname = clean_job(jobname)\n"
      ],
      "metadata": {
        "id": "7pYi5tmHe34I",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run_initial_prediction\n",
        "model_type = \"monomer (ptm)\" #@param [\"monomer (ptm)\", \"pseudo_multimer (v3)\", \"multimer (v3)\"]\n",
        "model = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "copies = 2 # @param [\"2\", \"3\"] {type:\"raw\"}\n",
        "cf.prep_inputs(sequence=sequence, jobname=jobname, copies=copies)\n",
        "cf.prep_model(model_type=model_type)\n",
        "cf.run_alphafold(model=model)\n",
        "ini_jobname = cf._jobname\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "CGunA5yseT4D",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title run_final_prediction\n",
        "model_type = \"monomer (ptm)\" #@param [\"monomer (ptm)\", \"pseudo_multimer (v3)\", \"multimer (v3)\"]\n",
        "#sym_method = \"ananas\" #@param [\"ananas\", \"symmdef\"]\n",
        "model = \"1\" #@param [\"1\", \"2\", \"3\", \"4\", \"5\", \"all\"]\n",
        "\n",
        "from string import ascii_uppercase\n",
        "import json\n",
        "ini_pdb = f\"{ini_jobname}/pdb/best.pdb\"\n",
        "\n",
        "sym_pdb = f\"{ini_jobname}/pdb/sym.pdb\"\n",
        "sym_json = f\"{ini_jobname}/pdb/sym.json\"\n",
        "cmd = f\"./ananas {ini_pdb} --symmetrize {sym_pdb} --json {sym_json}\"\n",
        "os.system(cmd)\n",
        "results = json.loads(open(sym_json,\"r\").read())\n",
        "if results is None:\n",
        "  sym_pdb = f\"{ini_jobname}/pdb/best_symm.pdb\"\n",
        "  sym_def = f\"{ini_jobname}/pdb/best_symm.txt\"\n",
        "  sym_log = f\"{ini_jobname}/pdb/best_symm.log.txt\"\n",
        "  cmd = f\"perl make_symmdef_file.pl -m NCS -p {ini_pdb} 2> {sym_log} 1> {sym_def}\"\n",
        "  print(\"WARNING: AnAnaS failed, attempting symmdef from Rosetta...\")\n",
        "  os.system(cmd)\n",
        "  for line in open(sym_log,\"r\").readlines()[:4]:\n",
        "    print(line.rstrip())\n",
        "else:\n",
        "  group = results[0][\"group\"]\n",
        "  rmsd = results[0][\"Average_RMSD\"]\n",
        "  print(f\"AnAnaS detected {group} symmetry at RMSD:{rmsd:.3}\")\n",
        "\n",
        "copies = !grep TER {sym_pdb} | wc -l\n",
        "copies = int(copies[0])\n",
        "cf.prep_inputs(sequence=sequence,\n",
        "               msa_method=\"single_sequence\",\n",
        "               template_mode=\"custom\",\n",
        "               pdb=sym_pdb,\n",
        "               chain=\",\".join(list(ascii_uppercase[:copies])),\n",
        "               jobname=jobname,\n",
        "               copies=copies,\n",
        "               do_not_align=True,\n",
        "               propagate_to_copies=False,\n",
        "               rm_template_seq=True)\n",
        "\n",
        "cf.prep_model(model_type=model_type,\n",
        "              use_initial_atom_pos=True)\n",
        "\n",
        "# center coordinates (not sure if this is needed)\n",
        "ini_pos = cf.af._inputs[\"template_all_atom_positions\"][0]\n",
        "cf.af._inputs[\"template_all_atom_positions\"][0] -= ini_pos[:,1].mean(0)\n",
        "\n",
        "cf.run_alphafold(model=model)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "inchOqANpvaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title display_best_result (optional) {run: \"auto\"}\n",
        "color = \"pLDDT\" #@param [\"pLDDT\",\"chain\",\"rainbow\"]\n",
        "show_sidechains = False #@param {type:\"boolean\"}\n",
        "show_mainchains = False #@param {type:\"boolean\"}\n",
        "color_HP = True\n",
        "\n",
        "cf.af.plot_pdb(color=color, show_sidechains=show_sidechains, show_mainchains=show_mainchains, color_HP=color_HP)\n",
        "predict.plot_plddt_legend().show()\n",
        "if not hasattr(cf,\"_aux_best\"):\n",
        "  cf._aux_best = cf.af._tmp[\"best\"][\"aux\"]\n",
        "predict.plot_confidence(cf._aux_best[\"plddt\"]*100, cf._aux_best[\"pae\"], cf._u_lengths * cf._copies).show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JG848xciCsIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download_prediction\n",
        "\n",
        "#@markdown Once this cell has been executed, a zip-archive with\n",
        "#@markdown the obtained prediction will be automatically downloaded\n",
        "#@markdown to your computer.\n",
        "\n",
        "# add settings file\n",
        "settings_path = f\"{cf._jobname}/settings.txt\"\n",
        "with open(settings_path, \"w\") as text_file:\n",
        "  if hasattr(cf,\"_input_opts\"):\n",
        "    for k,v in cf._input_opts.items():\n",
        "      text_file.write(f\"{k}={v}\\n\")\n",
        "  if hasattr(cf,\"_model_opts\"):\n",
        "    for k,v in cf._model_opts.items():\n",
        "      text_file.write(f\"{k}={v}\\n\")\n",
        "  if hasattr(cf,\"_run_opts\"):\n",
        "    for k,v in cf._run_opts.items():\n",
        "      text_file.write(f\"{k}={v}\\n\")\n",
        "# --- Download the predictions ---\n",
        "os.system(f\"zip -r {cf._jobname}.zip {cf._jobname}\")\n",
        "files.download(f'{cf._jobname}.zip')"
      ],
      "metadata": {
        "id": "GzFUdn9gFZgo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FAQ\n",
        "\n",
        "**Currently not supported**\n",
        "- Amber relax. To relax, use our [relax notebook](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/relax_amber.ipynb).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P-eF3aDCFFqG"
      }
    }
  ]
}